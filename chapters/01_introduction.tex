% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.
\chapter{Introduction}\label{chapter:introduction}

% overview 
Applying Neural Architecture Search (NAS) methods in a Federated Learning (FL) setting is an emerging field of study which we shall call \textit{FedNAS}. In this chapter we provide a motivation for the study of FedNAS and \textit{adaptation techniques} used by FedNAS methods to adapt NAS to the FL setting. Our motivation leads us to our research questions and finally, our proposed methodology to address them.

\section{Motivation}

% importance of FL and NAS
NAS and FL have independantly made significant progress in recent years and both are increasingly adopted in practice. 

% importance of NAS
The goal of NAS is the automation of the laborious neural network architecture engineering process responsible for so many of the advances made in Deep Learning in recent years \cite{nas_survey_2019}. The most recent wave of NAS research was initiated by \cite{nas_with_rl_2017} in 2017. Reinforcement Learning, a black-box optimization technique, was used to show that an automatically searched architecture can outperform handcrafted state-of-the-art architectures for image classification. NAS methods proposed early on were inefficient and a significant amount of research attention to address this improved the situation soon after. Newly developed efficient techniques tended to make use of the internals of the searched architectures (ENAS~\cite{enas_2018} and DARTS~\cite{darts_2019} are prominent examples). These techniques are still widely used today and have helped speed up NAS by orders of magnitude. Faster NAS has enabled more wide-spread adoption and consequently more experimentation for finding architectures with better accuracy, smaller size and faster training convergence. Architectures found via NAS now frequently improve upon state-of-the-art handcrafted architectures (e.g. NASNet~\cite{nasnet_2018}, AmoebaNet~\cite{amoebanet_2019}, MobileNetV3~\cite{mobilenetv3_2019}, EfficientNetV2~\cite{efficientnetv2_2021} and many more).

% importance of FL
FL on the other hand has become a viable privacy-enhancing choice for Collaborative Distributed Machine Learning \cite{cdml_2024}. Ever more valuable training data is collected on edge devices like smartphones referred to as \textit{clients}. Traditionally, this privacy-sensitive data is either not used at all or it is collected in a central location for training — greatly increasing the risk of exploitation by malicious actors. FL was invented to address this issue and allow the use of decentral training data without the data leaving the device it was generated on. Instead of performing training at a central location with a cluster of high-end machines, clients in FL train a shared model on their local data and coordinate weight updates to the shared model via a central server. FL "\textit{embodies the principles of focused collection and data minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning}" \cite{fl_advances_and_open_problems_2021}. Since its inception in 2016, FL has been adopted for various ML tasks in production systems by organizations like Google~\cite{gboard_fl_2018}, Apple~\cite{apple_fl_case_study_2025} and Owkin~\cite{owkin_fl_drug_discovery_in_prod_2022}.

% importance and usefulness of applying NAS to FL
Inevitably, users of FL expect to make use of existing NAS methods in the FL setting to produce architectures that achieve state-of-the-art accuracy. Apart from the generic benefits, NAS has been identified as a particularily good fit for the FL setting. A large body of work in NAS has focused on finding smaller architectures with reduced inference latency that still have reasonable accuracy \cite{nas_1000_papers_2023}. Such architectures are ideal for deployment on the often resource-constrained clients in the FL setting. \cite{fl_advances_and_open_problems_2021} notes that predefined architectures may not be an optimal choice for FL where user-generated data is not visible to model developers. They note that predefined architectures may contain components redundant for specific data sets or perform poorly on non-i.i.d. data (which is prevalant in FL). When the architecture search takes place on the clients, architectures can be adjusted according to the data and distribution present on them, yielding architectures better-suited to the data than architectures a model developer would pick. Dealing with with the distributed, non-i.i.d. data of the FL setting has been a key challenge for FedNAS methods and research into the matter has shown promise \cite{fednas_2021} \cite{rl_fednas_2021} \cite{fedoras_2022} \cite{finch_2024} \cite{peaches_2024}. Beyond architectures being tailored towards the data and distribution of each client, they can also be personalized to client's heterogenous computation and bandwidth budgets as shown by \cite{superfednas_2024} \cite{fedoras_2022} \cite{perfedrlnas_2024} \cite{decnas_2022}. 
% should I already mention what research has been done in this paragraph?

% NAS applied to FL: challenges
However, research in NAS methods has focused on a central NAS setting and the methods rely on assumptions that do not hold for the FL setting. These assumptions include an abundance of computational resources, homogeneinity of hardware for training and deployment, high availability of worker nodes, access to the entire dataset, access to the data distribution, etc. \cite{fl_advances_and_open_problems_2021}. This makes most centralized NAS methods unfeasable for direct application in the FL setting. Adopting NAS methods in the FL setting requires adapting them to the FL setting, giving rise to what we will call \textit{adaptation techniques}. In the following we briefly illustrate three adaptation techniques. 

% show that there is a wide variety of adaptation techniques
\begin{enumerate}
    % adapting supernets to FL 
    \item For example, naively training a one-shot supernet with a large search space by having each client train the entire supernet and aggregate weights of the entire supernet works for the cross-silo FL setting \cite{fednas_2021}, but doesn't translate to the cross-device setting. Clients in the cross-device setting generally have less compute resources and such a training scheme would result in detrimental completion times. Instead, in one FedNAS method \cite{fedoras_2022}, researchers have opted to reduce the compute burden on clients by only sampling and training subnets within the training budget of the client.
    % custom architecture weight aggregation
    \item Another problem arises when using standard FedAvg to average the architecture weights for DARTS-based supernets \cite{darts_2019}. Clients may tend towards architectures at the opposite ends of a spectrum, but averaging the architecture weights may select for an architecture that is not favored by any client. In \cite{efnas_2024} this is addressed by aggregating architecture weights into a probability distribution that can be used to sample likely architectures in the next communication round.
    % hereogeneity-aware tiering for a black-box optimization techniques
    \item Typically, when NAS methods are run in a central environment, they implicitly assume that the machines that NAS is performed on is homogenous and contribute equally to the architecture search. This assumption does not hold in the FL setting where the variance between compute resources of clients can be very large. Consequently, higher-end clients will tend to be used in training more and bias the searched architecture. \cite{network_aware_fed_nas_2025} adapts a NAS method to overcome this problem by by grouping clients into clusters according to their computational speed and network bandwidth. Small models get trained on low-end client clusters and larger models get trained on high-end client clusters.
\end{enumerate}

% why studying the adoptation techniques is important 
As shown by the examples above, the conditions of the FL setting break NAS methods in a way that requires novel adaptation techniques. While NAS research has focused on finding ways to perform NAS faster and finding better and smaller architectures, a key challenge of FedNAS methods lies in achieving these goals in spite of the challenges imposed by the FL setting — and adaptation techniques are key. No consolidated body of knowledge exists that can inform researchers on existing adaptation techniques and aid them in designing new techniques. To mend this, we propose a systematic review of adaptation techniques in this thesis. 

\section{Research Questions}

% TODO: sprinkle with examples

Making use of either NAS or FL on its own is a complex task. Combining them introduces even more possible knobs to turn on the system as a whole. There are many NAS methods to choose from and many challenges the FL setting imposes that can be optimized — surmounting in a vast amount of possible FedNAS methods. This leads us to our first research question:

\vspace{1em}
(RQ1) Which FedNAS methods already exist? 
\vspace{1em}

The vast amount of FedNAS methods result in a vast array of different adaptation techniques. Each FedNAS method makes use of a set of adaptation techniques to adapt a NAS method to FL. Some FedNAS methods have overlapping sets of adaptation techniques, but most sets of adaptation techniques are disjoint. Nonetheless, most literature does not draw clear boundaries around individual adaptation techniques, leading us to our second research question:

\vspace{1em}
(RQ2) How can we identify and cleanly separate adaptation techniques?
\vspace{1em}

Each adaptation technique pushes the system as a whole in a direction with regards to optimality towards FL challenges. Identifying this direction for each adaptation technique is important to understand potential trade-offs. This leads us to our third research question:

\vspace{1em}
(RQ3) Which FL challenges do the adaptation techniques address at what magnitude?
\vspace{1em}

Adaptation techniques are heavily dependant on the targeted FL challenge and used NAS method. Naturally, this does not allow for most adaptation techniques to work together. Additionally, some adaptation techniques are incompatible due to other reasons [TODO: what other reasons]. We would still like to know which existing adaptation techniques can be combined how, possbily paving the way for creating more powerful FedNAS methods tailored towards specific use cases. This leads us to our third research question:

\vspace{1em}
(RQ4) How can adaptation techniques be composed? How can we choose a set of adaptation techniques based on a use case?
\vspace{1em}

Once we have made it easy to mix and match adaptation techniques and understand in which direction they push the system, we can potentially identify combinations that could improve upon the status quo for selected subsets of FL challenges. Therefore our final research question is:

\vspace{1em}
(RQ5) Which combinations of adaptation techniques are particularily promising for certain sets of challengs in the FL setting?
\vspace{1em}

\section{Methodology}

% TODO: provide taxnomies/overivews:
% 1. categorize fednas papers based on NAS methods they adopt (use taxonomy from 1000 papers one-shot + black-box)
% 2. categorize fednas papers based on FL challenges they address (maybe constraints is a better word, constraints can be derive by spotting the difference between the centralized and FL setting)
% 3. put fednas papers in adaptation techniques bins
% 4. provide overview of development over time of the field
% 5. create UML diagram decomposing FedNAS method into pieces (combo of NAS method, targeted FL challenges and adaptation techniques)
% 6. pitch deck with demo examples
% UML entity relationship diagram could be helfpul, since I'm basically building a database of adaptation techniques

To tackle RQ1 we propose a systematic literature review with a PRISMA-style table for literature inclusion and exclusion. Once the set of literature to include is fixed, we address RQ2 by performing systematic coding of adaptation techniques according to ... [TODO: cite] and provide a concept definition together with discriminant rules that clearly separate one adaptation technique from others. 

For RQ3 we make use of prior work on a taxonomy of FL challenges \cite{fl_taxonomy_2024}. We will go over all adaptation techniques and discuss how the technique works towards, against or has no effect towards overcoming each of the FL challenges. The end result will be a table with the techniques on the y-axis and the FL challenges on the x-axis.

% compatability study? idea: mathematical "is-compatible-with" formulation
For RQ4 we propose building an is-compatible-with relation on the set of adaptation techniques. We achieve this by cross-examing each adaptation technique with every other one. To reduce the number of comparisons we make use of the taxonomy of NAS methods provided in \cite{nas_1000_papers_2023} and place each adaptation tecnique in one or multiple of the NAS method bins. Only adaptation techniques within the same bin need to be compared.

Finally, we make use of the is-compatible-with relation and our table discussing the FL challenges for each to select a few promising adaptation technique combinations and discuss their potential compared to the state of the art.