% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.
\chapter{Introduction}\label{chapter:introduction}

% What is the problem?
% What is the solution?
% Why is it relevant?


% Introduction: 
% - Describes the problem statement
% - illustrates why this is a problem and describes the contribution the thesis makes in solving this problem. 
% - Good introductions are concise, typically no longer than 4 pages.

% goal: about 2.5 pages

% Hook (1-2 sentences)
% Problem Statement: What's the problem? (3/4 page)
% Motivation: Why is it important to solve this problem? (3/4 page)
% Solution: How will this problem be solved? (3/4 page)

% hook
Applying Neural Architecture Search (NAS) methods in a Federated Learning (FL) setting is an emerging field of study which we shall call \textit{FedNAS}. In this chapter we provide a motivation for the study of FedNAS and the techniques used to adapt NAS to the FL setting. Our motivation leads us to our research questions and finally, our proposed methodology to address them.

% FL definition
%Federated Learning (FL) is a machine learning method whereby clients collaboratively train a model without sharing their data. This approach enhances the privacy of client data, increases the amount of data available to trainers that would otherwise be locked behind privacy barriers and makes it possible to use massive fleets of devices to train a model [cite Gboard].

\section{Motivation}

% importance of FL and NAS
% TODO: include importance of NAS within Deep Learning
NAS and FL have made significant progress in recent years and both are increasingly adopted in practice. 

% importance of NAS
NAS automates the laborious architecture engineering process responsible for so many of the advances made in Deep Learning in recent years. During the early stages of the most recent wave of NAS research since 2017 [cite: RL NAS Zoph et. al], NAS was mostly done through black-box optimization techniques and was computationally very expensive. In the following years, significant effort was directed towards reducing the computational burden with great success. NAS was no longer a technique only affordable to those with access to vast swathes of GPUs, but could now be done feasibly on a single GPU [TODO: cite GPU hours reduction]. Accessibility to NAS helped power a wide range of experimentation and ultimately resulted in techniques for finding architectures with better accuracy, smaller size and faster training convergence. Architectures found via NAS occupied the top spot of several benchmarks for 90\% of the time [TODO: cite].

% TODO: use quote from 2024 reflections paper instead?
% TODO: make shorter and less explanatory of FL
FL on the other hand has become a viable privacy-enhancing choice for Collaborative Distributed Machine Learning [cite]. Ever more valuable training data is collected on edge devices like smartphones (referred to as \textit{clients}), but collecting privacy-sensitive data in a central location greatly increases the risk of exploitation by malicious actors. FL was invented to make use of decentral training data without it ever having to leave the device it is being generated on — thereby enhancing the security of that data. Instead of collecting data to a central location and training a model on it there, \textit{clients} train a model on their local data and coordinates weight updates to the model through a central server. FL "\textit{embodies the principles of focused collection and data minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning}" \cite{fl_advances_and_open_problems_2021}. Since its inception in 2016, FL has gotten a great deal of research attention and is used in production for various purposes [TODO: cite].

% importance and usefulness of applying NAS to FL
Inevitably, users of FL expect to make use of existing NAS methods in the FL setting to produce architectures that achieve state-of-the-art accuracy. Apart from the generic benefits, NAS has been identified as a particularily good fit for the FL setting. A large body of work in NAS has focused on finding smaller architectures with reduced inference latency that still have reasonable accuracy [TODO: cite]. Such architectures are ideal for deployment on the often resource-constrained clients in the FL setting. \cite{fl_advances_and_open_problems_2021} notes that predefined architectures may not be the optimal choice when user-generated data is not visible to model developers. They note that predefined architectures may contain components redundant for specific data sets or perform poorly on non-i.i.d. data. Allowing architecture search to take place on the clients, where the architecture can be adjusted according to the data and distribution present, could yield architectures better-suited for the task at hand and several FedNAS methods have shown to  deal well with non-i.d.d. data [TODO: cite]. Architectures could even be personalized to each client's computational resource budget in a second stage. 
% should I already mention what research has been done in this paragraph?

% NAS applied to FL: challenges
However, research in NAS methods has focused on a central NAS setting and the methods rely on assumptions that do not hold for the federated setting. Assumptions that do not hold in the FL setting include an abundance of computational resources, homogeneinity of hardware for training and deployment, high availability of worker nodes, access to the entire dataset, access to the data distribution, etc. \cite{fl_advances_and_open_problems_2021}. This makes most centralized NAS methods unfeasable for direct application in the FL setting. Adopting NAS methods in the FL setting requires adapting them to the FL setting. 

% show that there is a wide variety of scenarios that leads to a wide variety of approaches 

% supernet approaches
For example, naively training a one-shot supernet with a large search space in the cross-device FL setting by having each client train the entire supernet and aggregate gradients would take weeks or months to complete [TODO: make realistic]. Instead, in one FedNAS method \cite{fedoras_2022}, researchers have opted to reduce the compute burden on clients by sending randomly sampled subspaces to clients for training and applied novel weight aggregation techniques tailored to aggregating architecture-related weights. In another [TODO: cite FINCH].

[TODO: Example 2]: custom architecture weight aggregation

% TODO: can this be used as example of adaptation of black-box optimization techniques? 
[TODO: Example 3] heterogeneity-aware tiering

% why studying the adoptation techniques is important 
% in what way does working towards the challenges imposed by NAS in FL help the field of NSA in general?
Compared to performing NAS centrally, the FL setting can seem antagonistic. The conditions of the FL setting break many NAS methods and require them to be adapted. While the focus of the NAS community at large is on finding ways to perform NAS faster and finding better and smaller architectures, a key challenge of FedNAS methods lies in making use of NAS methods robust. It has been noted before that NAS methods are notoriously fiddly and hence finding ways to make NAS work in FL may just provide means to do NAS more robustly in general. To find out how NAS techniques are made robust we need to study their adaptations. Understanding how NAS methods need to be transformed for the FL setting can make future transfer of NAS methods to FL easier.

% What are the "optimization objectives" that are inherently conflicting? How do these affect the adaptation techniques?

\section{Research Questions}

% TODO: sprinkle with examples

% what's the problem: no clear overview and analysis of techniques
Making use of either NAS or FL on its own is a complex task and combining them introduces even more possible knobs to turn to the system as a whole. There are many NAS methods to choose from and many challenges the FL setting imposes that can be optimized — surmounting in a vast amount of possible choices to make. This leads us to our first research question:

(RQ1) Which FedNAS methods exist? 

Most FedNAS methods focus on a small subset of the challenges imposed by the FL setting [TODO: cite/verify], resulting in a vast array of different adaptation techniques developed. Each FedNAS method uses a set of techniques to adapt a NAS method to FL. There is overlap between some of the adaptation techniques used by FedNAS methods, but most sets of adaptation techniques are disjoint. Nonetheless, most literature does not draw clear boundaries around adaptation techniques, leading us to our second research question:

(RQ2) How can we identify and cleanly separate out adaptation techniques?

Each adaptation technique pushes the system as a whole in a direction with regards to optimality towards FL challenges. Identifying this direction for each adaptation technique is important for informing trade-offs and picking Pareto optima. This leads us to our third research question:

(RQ3) Which FL challenges do the adaptation techniques address at what magnitude?

Adaptation techniques are heavily dependant on the targeted FL challenge and used NAS method. Naturally, this does not allow for most adaptation techniques to work together. Additionally, some adaptation techniques are incompatible due to other reasons [TODO: what other reasons]. We would still like to know which existing adaptation techniques can be combined how, possbily paving the way for creating more powerful FedNAS methods tailored towards specific use cases. This leads us to our third research question:

(RQ4) How can adaptation techniques be composed? How can we choose a set of adaptation techniques based on a use case?

Once we have made it easy to mix and match adaptation techniques and understand in which direction they push the system, we can potentially identify combinations that could improve upon the status quo for selected subsets of FL challenges. Therefore our final research question is:

(RQ5) Which combinations of adaptation techniques are particularily promising for certain sets of challengs in the FL setting?

\section{Methodology}

% TODO: provide taxnomies/overivews:
% 1. categorize fednas papers based on NAS methods they adopt (use taxonomy from 1000 papers one-shot + black-box)
% 2. categorize fednas papers based on FL challenges they address
% 3. put fednas papers in adaptation techniques bins
% 4. provide overview of development over time of the field
% 5. create UML diagram decomposing FedNAS method into pieces (combo of NAS method, targeted FL challenges and adaptation techniques)

We therefore propose a detailed analysis of the existing approaches to applying NAS to FL in this Bachelor's thesis.
