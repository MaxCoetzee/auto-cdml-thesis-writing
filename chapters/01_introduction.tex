% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.
\chapter{Introduction}\label{chapter:introduction}

% hook
%% hook a) "what is the domain and why is it important?"
Both Neural Architecture Search (NAS) and Federated Learning (FL) have made significant progress independently in the past decade, and both are increasingly adopted in practice. To benefit from the advantages of NAS methods in FL, researchers have started combining them by using NAS in the FL setting. 
%% => opening paragraph begs for
%%%      1. explanations of NAS and FL
%%%      2. why each is important
%%%      3. why applying NAS in FL is important 

%%% NAS explanation and why is it important
Neural Architecture Search (NAS) automates the process of engineeering neural network architectures for Deep Learning application domains~\cite{nas_survey_2019}. This stands in contrast to the traditional, labourious approach to applying Deep Learning. Traditionally a team of domain experts and Deep Learning experts engineer a well-suited architecutre based on expert knowledge and trial-and-error. NAS does not only reduce manual effort, but can also be used to find architectures that perform better than architectures humans have designed for specific application domains~\cite{nasnet_2018}~\cite{amoebanet_2019}~\cite{mobilenetv3_2019}~\cite{efficientnetv2_2021}.

%%% FL explanation and why it is important 
Federated Learning (FL) is a machine learning method whereby clients collaboratively train a model without sharing their data. Clients train a shared model on their local data and coordinate weight updates to the shared model via a central server. FL was originally invented by Google to enable the usage of the increasing volume of privacy-sensitive data stored on edge devices, but distributed data silos (at the organisational level) containing privacy-sensitive data have become another use case. The former is referred to as the \textit{cross-device} FL setting and the latter as the \textit{cross-silo} FL setting. Before FL, it was typical for both kinds of distributed privacy-sensitive data to either not be used at all for machine learning or it was collected in a central location for training â€” creating the risk of a major breach by malicious actors.

%%% why NAS for FL is important: generic benefits and it is a good fit 
By using NAS in the FL setting, researchers not only benefit from the generic benefits of NAS mentioned above, but from several advantages specific to the FL setting:
\begin{itemize}
    \item A large body of work in NAS focuses on finding smaller architectures with reduced inference latency that still have reasonable accuracy \cite{nas_1000_papers_2023}. Such lightweight architectures are ideal for deployment on the resource-constrained clients in the cross-device FL setting.
    \item \cite{fl_advances_and_open_problems_2021} note that predefined architectures may not be an optimal choice for FL. Since client data is not visible to model developers, a predefined architecture selected by model developers may contain components redundant for generalizing well from certain client data sets.
	\item Predefined architectures may perform poorly on another prevalent characteristic of the FL setting: data that is not independently and identically distributed (non-i.i.d.). % [TODO: why?]
\end{itemize}

%% hook b) "What is the overall problem or situation in that domain?"
%%% overall problem in FedNAS domain: NAS for FL breaks
%%% TODO: Justify use of "However" or leave it out
However, using NAS in the FL setting is not straightforward. NAS methods described in the literature typically assume a centralized setting as opposed to the distributed FL setting. When used in a centralized setting, NAS methods can assume i) that worker nodes will have high availability, ii) that the entire training dataset can be accessed, iii) that the distribution of the training data can be inferred, etc. These assumptions do not hold for the FL setting, making most NAS methods unfeasable for direct application in the FL setting. Instead, researchers need to adapt NAS methods to the FL setting, giving rise to what we shall call \textit{FedNAS} methods.
%%% Meta-Comment: I make use of numbering i-iii, because the descriptions of the assumptions are longer phrases and I feel this helps the reader navigate them. If the stated assumptions were only separated by commas, the reader might get lost in the length of the sentence.

% TODO: is the following relevant: Why do the challenges for FL in general apply specifically for NAS for FL s well asWhy are the challenges the same?

%%% get more specific about how NAS breaks => challenges
% TODO: better challenge descriptions
Adapting NAS methods to the FL setting poses a set of challenges similar to the challenges faced by researchers making use of FL in general. We shall make use of a prior work~\cite{fl_taxonomy_2024} that organizes these challenges into seven classes of challenges: % TODO: Should I inlclude why we can use the  taxonomy for our challenges  eventhough it's original purpose is different?
\begin{itemize}
    \item \textbf{Heterogeneity}: dealing with hardware and data heterogeneity
    \item \textbf{Fairnes}: mitigating bias caused by more performant devices contributing more to the trained gradients
    \item \textbf{Communication Efficiency}: dealing with the high network latency and low bandwith of edge devices
    \item \textbf{Computation Efficiency}: hard to train ML models on low end edge devices
    \item \textbf{Client selection}: clients contribute different amounts of information towards training the shared model, it's hard to select the right clients for a communication round and select clients that will be available for the next communication round
    \item \textbf{Security}:
    \item \textbf{Privacy}:
    \item \textbf{Fault-Tolerance}: clients are not always available and stragglers need to be dealt with
\end{itemize}
% reforemulate research directions as challenges instead? => not sure

Each FedNAS method employs several \textit{adaptation techniques} dependant on a) the type of NAS method it adapts and b) the class of challenges the FedNAS method aims to overcome. For example, naively using a supernet-based NAS method in the cross-device FL setting by having each client train the entire supernet, % "training the entire supernet" is ambiguous, need to reformulate
would result in detrimental completion times. This embodies the computational efficiency challenge class, and one FedNAS method~\cite{fedoras_2022} overcomes it by \textit{adapting} the subnet sampling process of X NAS method, such that only subnets within the client's training budget get selected for training.

% why is it relevant that researchers develop new FedNAS methods?
% why is fragemented literature a practical problem?

%%% why is literature review on adaptation techniques relevant?
%%% TODO: maybe add reason why a regular FedNAS user might create their own FedNAS method? Not only reasearcher do this
%%% - every problem is different => off-the-shelf solutions don't work
%%% - need composable adaptation techniques to create fednas methods 
Researchers constantly create new FedNAS methods, either to adapt new NAS methods to the FL setting or to adapt NAS methods in new ways to overcome different sets of challenge classes. To this end, it is useful to use existing literature on FedNAS methods and avoid re-inventing adaptation techniques for overcoming each of the challenge classes. A considerable amount of literature on FedNAS methods has appeared in recent years, resulting in a large number of novel adaptation techniques.

% Gap
%% Situate in research: What are the conclusions of existing literature for that problem / situation in this domain? 
%% TODO: flesh out
There have been prior surveys on FedNAS methods~\cite{fl_to_nas_survey_2021}~\cite{nas_hpo_fl_survey_2023}~\cite{multi-objective_methods_in_fl_2025}. \cite{fl_to_nas_survey_2021} is an early work that characterises FedNAS methods on the whole into offline vs. online search and single- vs. multi-objective variants. \cite{nas_hpo_fl_survey_2023} ... . \cite{multi-objective_methods_in_fl_2025} ... . 

%% identify opportunity, explain relevance: What is the problem or issue with that existing literature?
None of the prior literature surveys provide a consolidated body of knowledge that can inform researchers on existing adaptation techniques and the challenge classes they overcome. \cite{fl_to_nas_survey_2021} was limited by the small amount of literature available at the time. \cite{nas_hpo_fl_survey_2023} only surveys methods that use NAS and Hyperparameter Optimization together, leaving out a large part of the FedNAS literature. They also only analyze FedNAS methods on the whole. \cite{multi-objective_methods_in_fl_2025} looks at the application of multi-objective optimization methods in Federated Learning in general, and views FedNAS as a specific case for which a multi-objective optimization perspective can be useful. Since only multi-objective optimization methods are considered, a large part of the FedNAS literature is left out as well. 

Extracting the adaptation techniques used by FedNAS methods, would allow researchers to easily make use of this knowledge to compose new FedNAS methods tailored to overcoming a specific set of challenge classes relevant to them. However, prior surveys focus on FedNAS methods on the whole instead of individual adaptation techniques used by FedNAS methods. Each of the surveys also only analyses a fraction of the literature. This means that adaptation techniques are scattered throughout the increasingly large volume of FedNAS literature, leading us to our research question:

% TODO: reformulate better
\vspace{1em}
(RQ) \textbf{How and which challenge classes do adaptation techniques described in the literature overcome?}
\vspace{1em}

% Study: How investigate? Process, context & why?
%% Indicate that this study addresses that problem or issue and state how.
%% Describe the study, sample, and method for addressing that problem or issue.
To mend this, we perform a systematic literature review of adaptation techniques in this thesis. We divide our approach into 5 steps:

\begin{enumerate}
    \item \textbf{Literature Selection:} We follow the guidelines and flow diagrams provided by PRISMA 2020 \cite{prisma_2020} for inclusion and exclusion of papers and perform forward and backwards citation searching. Each paper contains one or more FedNAS methods. 
    \item \textbf{Adaptation Technique Extraction:} Once the set of included papers is fixed, we analyse each paper individually, extracting the adaptation techniques it uses and summarising them.
    \item \textbf{Simplify Adaptation Technique Extraction:} We then merge conceptually highly-similar adaptation techniques into a single representative adaptation technique.
    \item \textbf{Categorise Adaptation Techniques:} After merging, we categorise the adaptation techniques based on conceptual similarity and deliver a taxonomy of adaptation techniques.
    \item \textbf{Map FL Challenge Types onto Adaptation Techniques:} Next, we discuss how each adaptation technique works towards, against, or does not affect overcoming each of the FL challenge classes and provide a table with an overview as an end result. 
\end{enumerate}
 
% Conclusion
% Describe what you found.
% State explicitly how these findings extend and contribute to existing knowledge.

% Outline

